# 爬虫总结，仅供参考

```markdown
## 1. 爬虫的简介与原理 
1.1 什么是爬虫?
		就是一段模拟成浏览器的程序
1.2 为什么要用爬虫?
		为了获取数据
1.3 爬虫为什么可以起作用? 
		因为遵循了互联网的本质:请求--响应
1.4 怎么做一个爬虫? 
		依照原理，发送http请求(伪装成和浏览器一样)，解析http响应
## 2. requests
2.1 发送无参get请求
2.2 发送有参get请求
2.3 发送有惨post请求(无参post请求没有意义，不可能发送无参post)
2.4 模拟headers
2.5 模拟cookies
2.6 模拟代理ip
2.7 requests的session机制
2.8 源码分析 requests.get requests.post session.get session.post Request Response
## 3. scrapy
3.1 scrapy的由来(从对requests的封装推导出scrapy的各个组件以及工作流程)
3.2 scrapy的开发流程(编写item，spider，pipeline，强调一个请求对应一个响应对应一个解析函数) 
3.3 scrapy的额外功能(中间件，crawlspider，imagepipeline，日志，自动限速，允许异常状态码，提
高并发量，恢复与暂停)
3.4 scrapy源码分析 spider scheduler Downloader engine Request FormRequest Response
(item,pipeline和中间件不用看) 3.5 scrapy的信号机制(暂定)
## 4. 高效率爬虫
4.1 分布式进程与requests集成
4.2 scrapy-redis分布式爬虫(scrapy做分布式，共用一个redis) 
4.3 aiohttp异步框架
4.4 fastrequests自己封装的异步框架
4.5 分布式爬虫框架设计(8个组件的大图)
## 5. 常见反爬以及解决方案(注:在模拟headers，cookies以后遇到的反爬，做爬虫不管对方是否反爬，一定加上这 两个，来避免这个问题)
5.1 封ip 
		解决方案:使用随机ip来提高ip地址的可用性 
		案例网站:拉钩招聘数据，西刺代理
5.2 封账号 
		解决方案:使用多个账号做随机cookie 
		案例网站:招聘狗简历数据
5.3 js加密
		解决方案:无界面浏览器和使用python代码执行js 
		案例网站:网易云音乐评论 中国商标网 中国国际航空的登录
5.4 验证码
5.4.1 普通数字字母验证码 
		解决方案:打码平台和验证码识别 
		案例网站:人人网
5.4.2 滑块验证码
		解决方案:
		1. 使用pillow识别出滑块验证码的缺口，计算出要移动的距离
		2. 将移动距离分为多个小段，再用selenium控制鼠标移动，前面几个小段加速移动，后面几个小段减速移动
5.4.3 点击字或者特殊符号
		解决方案:
		1. 使用百度接口或者pillow识别出字体或者特殊符号的坐标
		2. 将鼠标移动到字或者特殊符号对应的坐标，再触发点击事件 案例网站:招聘狗企业登录 知乎登录 当当网登录 12306购票
5.5 响应中文乱码 
		解决方案:用原生二进制字符串手动解码(编码格式从页面的charset找，如果没有，一般为utf-8) 
		案例网站:国家信息安全漏洞共享平台
5.6 只显示定量的数据 
		解决方案:认真分析网站，尽可能多的匹配查询条件，尽可能多的找不同的获取数据的url(也称为API) 
		案例网站:百度失信被执行人数据
5.7 响应数据非json非html 
		解决方案:当做字符串处理，用正则表达式配合字符串切割 
		案例网站:百度失信人被执行人数据 球探网数据 中国竞彩网
5.8 自定义字体 
		解决方案:下载字体文件，用python的fontTools库解析字体文件，获得字符映射。
		1. 若不是每次动态变化的字体文件，可以手动写字与字符的映射来获得数据。
		2. 若是每次动态变化的字体文件，则需要识别字体轮廓对应的字，再动态做字与字符的映射来获取数据 
		案例网站:58简历数据 猫眼电影数据
5.9 评分数据背景图片 
		解决方案:下载对应的背景图片和css文件，根据css文件的样式来计算图片的偏移量，再用pillow切出对应图片对应的数字，并识别出数字内容 
		案例网站:大众点评数据
5.10 视频文件是m3u8格式，即多个ts文件 
		解决方案:找到m3u8文件对应的url，获得每个ts的url，再依次下载ts文件，并以二进制的形式追加到同一个文件中
		案例网站:哔哩哔哩 韩剧tv网
5.11 图片，文件，音频数据采集 
		解决方案:找到图片，文件，音频对应的url，发请求获得二进制流，并以wb形式写入到本地文件中 
		案例网站:百度图片等网站
5.12 动态变化的cookie 
		解决方案:设置全局cookie，当cookie失效的时候，重新发请求到获得cookie的url，然后更新掉全局cookie
    案例网站:大街网招聘数据
5.13 数据在多个url中 
		解决方案:认真分析网站，找到每个url对应的部分数据，再合并数据 
		案例网站:之前的中国东方航空，后也改了，现在暂时没遇到
5.14 请求参数是Request Rayload，即json参数 
		解决方案:传json格式的参数(即字典格式，但参数为json)，不传params和data 
		案例网站:协程的国际港澳台机票数据
5.15 响应是压缩流(即响应数据全是乱码) 
		解决方案:在headers中不传accept-encoding，或者使用gzip的包进行解压 
		案例网站:韩剧tv网
5.16 响应使用FM.view进行渲染
		解决方案: 当做字符串使用正则卡出含有数据的FM.view，再切割掉无用的字符，然后用json转为字典,再取出对应的html页面，再用xpath进行解析
		案例网站:微博
5.17 APP采集 解决方案:
		1. 在电脑上安装一个安卓模拟器和一个抓包工具
		2. 设置抓包工具的监听端口以及允许远程代理，并重启抓包工具
		3. 在模拟器上安装要采集的APP，且将模拟器的wifi打开，在高级设置中选择手动代理，填入电脑的ip地址，以及抓包工具监听的端口
		4. 点击模拟器的APP，查看在抓包工具中抓到的url以及对应响应(注:绝大多数APP都是通过JSON来做数据传输，所以只看JSON即可) 
		案例网站:今日头条
5.18 APP使用Https请求 
		解决方案:
		1. 在模拟器自带的浏览器的地址栏中输入手动代理的ip地址和端口，看到抓包工具的主页 
		2. 点击最下方的链接，下载并安装证书(随便给证书起个名字即可)
		3. 设置抓包工具的配置，允许https请求，且忽略错误，并重启抓包工具
		4. 点击模拟器的APP，查看请求对应数据
		案例网站:抖音
5.19 APP使用了随机签名 
		解决方案:极其复杂，需要大量前置知识，一两句说不清，简单描述下思路
		前置知识:
		1. 签名本身使用的RSA的原理(即公钥私钥认证)
		2. 安卓签名工具有两种，jarsign和signapk，分别对应的私钥文件不一样，jarsign工具签名时使用的keystore文件，signapk工具签名时使用的是pk8,x509.pem文件 
		3. 安卓反编译
		思路:
		1. 对安卓进行反编译，查看其使用的签名方式
		2. 使用python代码模拟签名加密方式(MD5或者SHA1)，产生对应私钥文件 3. 抓包工具抓到请求以后携带者签名和私钥发送请求，解析响应
## 6. 特殊网站
6.1 世纪佳缘 百合网 
		网站介绍:数据量大且全，基本没有反爬，可以快速积攒数据
6.2 万行教师网 
		网站介绍:数据量小但全，基本没有反爬，但是服务器响应较慢，可以使用分布式或者异步框架提高爬虫效率
6.3 智联招聘 
		网站介绍:在浏览器中只能看懂12页数据，但是通过代码是可以获取更多数据
6.4 微博 
		网站介绍:自带游客系统(实际上和强制登录的思路一样，验证一个cookie)，且可以通过将headers中UA设置为爬虫的UA(含有spider即可)来绕过 
6.5 中国商标网
		网站介绍:综合查询入口使用js加密了参数，且可以识别出无界面浏览器，但在公告查询的入口中，基本没 做反爬，而且可以在别的网站获取到商标数据，且没有反爬
6.6 中国文书网 
		网站介绍:每次查询都需要携带一个验证码
## 7. 补充知识概念
7.1 牢记爬虫的目的是以数据为导向，为了获取数据，不是为了突破反爬 
7.2 牢记爬虫的原理是请求响应，是模拟成浏览器的请求
7.3 牢记一切响应都可以当做字符串处理
## 8. 小手段
8.1 对于需要登录且破解登录极其复杂的网站，不如直接携带登录标识的cookie 
8.2 有些网站有登录，但不代表一定要登录以后才能获取数据 
8.3 当网站的反爬极其困难时，不妨去该网站对应的APP，一般APP的反爬都比较简单，或者看看其他网站是否有 这个网站的数据
8.4 当APP的反爬极其困难时，不妨去该APP对应的网站看看
8.5 有些网站为了搜索引擎更快的收录，会对搜索引擎的爬虫开发更高的权限，所以可以将UA模拟成搜索引擎试试
```

