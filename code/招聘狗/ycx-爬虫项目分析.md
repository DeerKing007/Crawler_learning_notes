  # 爬虫项目串联

### 一、爬虫的基本流程

1.发送请求

2.获取相应

3.解析相应

4.数据存储





**招聘狗：**

1.获取url    反爬手段：cookie 



resumeHtmlId 

详情页：获取简历页，xpath解析



推荐：requests



**反爬手段：**

1.验证码：中国商标网

2.限制数量：京东、智联

3.封ip：拉勾网

4.js加密：58同城

5.数据为背景图片：大众点评

6.社交类网站---vb



爬虫  项目 ---  坑 反爬





**scrapy：**

1.进程池、cookies在中间件中

2.headers在setting.py





